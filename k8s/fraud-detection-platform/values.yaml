# Default values for fraud-detection-platform.

# ------------------------------------------------------------------------------
# Dependencies Configuration (Bitnami Charts)
# ------------------------------------------------------------------------------

# Kafka
kafka:
  enabled: true
  image:
    tag: 3.6.1 # Override to generic tag
  replicaCount: 1
  zookeeper:
    enabled: false
  provisioning:
    enabled: true
    topics:
      - name: transactions
        partitions: 1
        replicationFactor: 1

zookeeper:
  enabled: true
  image:
    tag: 3.9.1 # Override to generic tag
  replicaCount: 1
  auth:
    enabled: false
  allowAnonymousLogin: true

# Redis
redis:
  enabled: true
  architecture: standalone
  auth:
    enabled: false

# PostgreSQL
postgresql:
  enabled: true
  auth:
    username: admin
    password: password
    database: fraud_detection

# MinIO
minio:
  enabled: true
  image:
    repository: minio/minio
    tag: latest
  command: ["/bin/sh", "-c"]
  args: ["minio server /data --console-address :9001"]
  auth:
    rootUser: minioadmin
    rootPassword: minioadmin
  defaultBuckets: "lake"

# ------------------------------------------------------------------------------
# Application Microservices
# ------------------------------------------------------------------------------

# Transaction Generator
generator:
  image:
    repository: weather-stream-analytic-transaction-generator
    pullPolicy: Never # Uses local docker image
    tag: latest
  resources: {}

# Fraud Detector (Spark)
detector:
  image:
    repository: weather-stream-analytic-fraud-detector
    pullPolicy: Never
    tag: latest
  resources: {}
  env:
    SPARK_MASTER: "k8s://https://kubernetes.default.svc:443" # Running in client mode or cluster mode?
    # For simplicity in this initial port, we might run Spark in "standalone" mode within a pod
    # OR submit to K8s. Let's start by replicating the docker-compose setup (Standalone Master/Worker Deployment)
    
spark:
  master:
    image: apache/spark:3.5.0
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"
  worker:
    image: apache/spark:3.5.0
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"

# Dashboard
dashboard:
  image:
    repository: weather-stream-analytic-dashboard
    pullPolicy: Never
    tag: latest
  service:
    type: LoadBalancer # Expose to localhost
    port: 8501

# Airflow
airflow:
  enabled: false # Skipping Airflow for initial K8s port to keep it simple, or we can use the official Helm chart
